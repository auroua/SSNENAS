# Self-supervised Representation Learning for Evolutionary Neural Architecture Search

This repository contains code for paper [Self-supervised Representation Learning for Evolutionary Neural Architecture Search](https://arxiv.org/abs/2011.00186).

If you use the code please cite our paper.

    @article{Chen2020SSNENAS,
        title={Self-supervised Representation Learning for Evolutionary Neural Architecture Search},
        author={Chen Wei and Yiping Tang and Chuang Niu and Haihong Hu and Yue Wang and Jimin Liang},
        journal={ArXiv},
        year={2020},
        volume={abs/2011.00186}
    }

## Prerequisites
* Python 3.7
* Pytorch 1.3
* Tensorflow 1.14.0
* ptflops `pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git`
* torch-scatter `pip install torch-scatter==1.4.0`
* torch-sparse `pip install torch-sparse==0.4.3`
* torch-cluster `pip install torch-cluster==1.4.5`
* torch-spline-conv `pip install torch-spline-conv==1.1.1`

## Searching Environment
* Ubuntu 18.04
* cuda 10.0
* cudnn 7.5.1

## Usage
#### Clone this project
```bash
git clone https://github.com/auroua/SSNENAS
cd SSNENAS
```

#### Download models and set the variables in configs.py to point to the correct file.


#### Data Preparation
##### NASBench-101
1. Down load `NASBench-101` dataset first. We only use the `nasbench_only108.tfrecord` file.
2. Set the variable `nas_bench_101_base_path` in `config.py` to point to the folder containing the file `nasbench_only108.tfrecord`.
3. Run the following command to generate data files that are required by the code.
```bash
python nas_lib/data/nasbench_101_init.py
```

##### NASBench-201
1. Down load the `NASBench-201` dataset first. In this experiment, we use the `NASBench-201` dataset with version `v1_1-096897`, and the file name is `NAS-Bench-201-v1_1-096897.pth`.
2. Set the variable `nas_bench_201_base_path` in `config.py` to point to the folder containing the file `NAS-Bench-201-v1_1-096897.pth`.
3. Run the following command to generate data files that are required by the code.
```bash
python nas_lib/data/nasbench_201_init.py --dataname cifar10-valid
python nas_lib/data/nasbench_201_init.py --dataname cifar100
python nas_lib/data/nasbench_201_init.py --dataname ImageNet16-120
```

#### Prediction Analysis
##### SS_RL
Run the following command to train the model that contains the architecture embedding part of the neural predictor.
###### NASBench-101 search space
```bash
# save_dir: the output of model weights
python tools_predictors/train_predictor_rl.py --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/' --search_space 'nasbench_101' 
```

###### NASBench-201 search space    
```bash
# save_dir: the output of model weights
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_predictors/train_predictor_rl.py --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/' --search_space 'nasbench_201' --dataname 'cifar10-valid' 
```

##### SS_CCL
Run the following command to train the model that contains the architecture embedding part of the neural predictor.
###### NASBench-101 search space
```bash
# batch-size: Parameter N in Algorithm 1. The training batch size that determines the size of the negative pair. If you are using multiple gpus, multiple batch-size with the gpu count.
# train_samples: Parameter M in Algorithm 1.
# min_negative_size: Determine the number of negative pairs, which is slightly small than batch-size.
# multiprocessing-distributed: Using multiple gpus, set to True, else set to False.
# gpu: multiple gpus set to None, else set to 0.
python tools_predictors/train_predictor_ccl.py --search_space 'nasbench_101' --batch-size 40000 --train_samples 20000 --batch_step 1000 --min_negative_size 39850 --gpu 0 --multiprocessing-distributed False --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### NASBench-201 search space    
```bash
# batch-size: Parameter N in Algorithm 1. The training batch size that determines the size of the negative pair. If you are using multiple gpus, multiple batch-size with the gpu count.
# train_samples: Parameter M in Algorithm 1.
# min_negative_size: Determine the number of negative pairs, which is slightly small than batch-size.
# multiprocessing-distributed: Using multiple gpus, set to True, else set to False.
# gpu: multiple gpus set to None, else set to 0.
python tools_predictors/train_predictor_ccl.py --search_space 'nasbench_201' --batch-size 10000 --train_samples 5000 --batch_step 1000 --min_negative_size 9850 --gpu 0 --multiprocessing-distributed False --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

After the above pre-training, update the parameters `ss_rl_nasbench_101`, `ss_rl_nasbench_201`, `ss_ccl_nasbench_101`, and `ss_ccl_nasbench_201` to the pre-trained model file which is generated by the above code.

##### Predictive Performance Comparison
###### NASBench-101 search space
```bash
# predictor_list: The predictor type, it is a list type.
# load_dir: the pre-trained model paths, which is corresponding with the predictor types. 
python tools_predictors/predictor_finetune.py --predictor_list 'SS_RL' 'SS_CCL' --search_space 'nasbench_101' --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### NASBench-201 search space
```bash
# predictor_list: The predictor type, it is a list type.
# load_dir: the pre-trained model paths, which is corresponding with the predictor types.
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_predictors/predictor_finetune.py --predictor_list 'SS_RL' 'SS_CCL' --search_space 'nasbench_201' --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### Visualize Results
Run the following command to visualize the comparison of algorithms
```bash
# result_path: the save_dir of the above commands.
python tools_predictors/predictor_finetune.py --result_path '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

#### Fixed Budget NPENAS
##### NASBench-101 search space
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_101 --algo_params nasbench_101 --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```
##### NASBench-101 search space fixed budget.
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_101 --algo_params nasbench_101_fixed --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```
##### NASBench-201 search space
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_201 --algo_params nasbench_201 --dataname 'cifar10-valid' --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```

##### Visualize Results
Run the following command to visualize the comparison of algorithms. *Change the `save_dir` to the path of `save_dir` in the above step.*
```bash
python tools_close_domain/visualize_results.py --search_space nasbench_201 --save_dir /home/albert_wei/Disk_A/train_output_npenas/npenas_201/ --draw_type ERRORBAR
```

##### Encoding analysis    
```bash
# search_space: ['nasbench_101', 'nasbench_201']
python tools_predictors/encoding_compare.py --search_space nasbench_201
```
##### Predictive performance comparison
```bash
# modify the save_dir parameter
python tools_predictors/predictor_comparison.py --search_space nasbench_101 --gpu 0  --save_dir /home/aurora/data_disk_new/train_output_2021/darts_save_path/
```

##### Performance comparison of normalization GED
```bash
# modify the save_dir parameter
python tools_predictors/predictor_comparison_ged.py --gpu 0 --save_dir /home/aurora/data_disk_new/train_output_2021/darts_save_path/
```

##### NASBench-201 search space
##### Generate random neural architectures
```bash
# modify the save_dir parameter
python tools_darts/gen_darts_archs.py --nums 50000 --save_dir '/home/aurora/data_disk_new/train_output_2021/darts_save_path/darts.pkl'
```

##### Convert the random genotype into neural architecture
```bash
# save_dir: point to the folder that contains the genotype files generated by the above step
python tools_darts/convert_gen_data_to_architectures.py --save_dir /home/aurora/data_disk_new/train_output_2021/darts_save_path/models/
```

##### Pre-train using the self-supervised center contrastive learning
```bash
# darts_arch_path: point to the folder that generated by the above step
# The meaning of parameter batch-size, train-samples, min_negative_size can be found in our paper
python tools_predictors/train_predictor_ccl.py --darts_arch_path /home/aurora/data_disk_new/train_output_2021/darts_save_path/architectures/part3_partial.pkl --save_dir /home/aurora/data_disk_new/train_output_2021/darts_save_path/  -b 10000  --train_samples  4000 -bs 500  --min_negative_size  9900
```

##### Modify the `ss_ccl_darts` in `config.py` that point to the self-supervised pre-trained model file

##### Darts Search Space
```bash
# darts_arch_path: point to the folder that generated by the above step
# The meaning of parameter batch-size, train-samples, min_negative_size can be found in our paper
python tools_darts/train_multiple_gpus_open_domain.py --gpus 1 --seed 11 --budget 100  --save_dir /home/aurora/data_disk_new/train_output_2021/darts_save_path/
```
##### The parameter of how many neural architectures evaluated can be modidfied in file nas_lib/params.py  line 171 the parameter fixed_num

##### How to rank the search results, train the best model and evaluate the model can reference [NPENAS](https://github.com/auroua/NPENASv1).

##### Test the retrained architecture with the following command
```bash
model_name: the id of the searched architecture
save_dir: The model file should in a folder, and the folder name is `model_pkl`. This dir point to the path that contains the `model_pkl` folder. 
model_path: this path points to the saved weights file.  
python tools_darts/test_darts_cifar10.py --model_name e678ee620e52436f6e2f36d0396c1f9baf994a78e64242d629aad927b0eb0057.pkl --save_dir /home/albert_wei/Desktop/CIM-Revise-R2/ssnenas_darts_results_new/models/ --model_path /home/albert_wei/Desktop/CIM-Revise-R2/ssnenas_darts_results_new/seed_1/model_best.pth.tar

```

**Visualize the searched normal cell and the reduction cell, and this architecture achieves a testing error `2.41%`.**

![normal_cell](/images/normal_darts.png)
![reduction_cell](/images/reduction_darts.png)


You can download the best architecture's genotype file from [genotype](https://pan.baidu.com/s/1dfgE97Iajqy3LGd-rSLgHw) with extract code `2h3y`. The address of the retrained weight file is [pth](https://pan.baidu.com/s/1Z2O71eu9V3i6rEVxgjoEJA) with extract code `wxpc`.
You can use the command in step 5 to verify the model.

## Hardware Configuration

| CPU       | GPU     | Memory Size    |
| :-------------: | :----------: | :-----------: |
|  Intel Xeon E5-2650 v4 *2 | Titan V * 6   | 128G    |

## Self-supervise representation learning models
| model type       | link     | password    |
| :-------------: | :----------: | :-----------: |
|  ss_ccl_nasbench_101_140k | [link](https://pan.baidu.com/s/1RaZmbMhPbE2TwUrfNaBlgg)   | dvba    |
|  ss_ccl_nasbench_201 | [link](https://pan.baidu.com/s/1B96bbJEc_LBzDNnvavctBQ)   |  7q4f   |
|  ss_ccl_darts | [link](https://pan.baidu.com/s/12dUNJImx6Yt-g82sOrdK3g)   |  w6k7   |
|  ss_rl_nasbench_101_300 | [link](https://pan.baidu.com/s/14jKMQ1SeMGvQZZOYrGYtAw)   |   kjtb  |
|  ss_rl_nasbench_201_1000 | [link](https://pan.baidu.com/s/1J9yah4aGtFYizLaAxwCw7A)   |  p447   |
|  ss_rl_nasbench_201_wo_normalization | [link](https://pan.baidu.com/s/1-aKGDZ71XJ375ofQuA6ETA)   |  tqmb   |
|  ss_ccl_nasbench_101_10k | [link](https://pan.baidu.com/s/1pTH0i7zjVG2eCay5nZw-wA)   |  nr8h   |
|  ss_ccl_nasbench_101_40k | [link](https://pan.baidu.com/s/1X9Nb6EXR1Zu2Bsrb5xRm6A)   |   qy3u  |
|  ss_ccl_nasbench_101_70k | [link](https://pan.baidu.com/s/1OB2qgxHukpgxTceKjDw0oQ)   |   tcjy  |
|  ss_ccl_nasbench_101_100k | [link](https://pan.baidu.com/s/1heptf87cH7jUWl04cayUjw)   |  f5jj   |


## Experiment Results
|  Experiment      | visualization script* | link     | password    |
| :-------------: | :----------: | :----------: | :-----------: |
|  predictor_finetune_nasbench_101 |  tools_predictors/visualize/visualize_predictor_finetune.py   | [link](https://pan.baidu.com/s/19OynL_oNivRhvfgpqHxNtQ)   | r94w    |
|  predictor_finetune_nasbench_201 |  tools_predictors/visualize/visualize_predictor_finetune.py         |[link](https://pan.baidu.com/s/13ba7U6z8zb18XGFt2k6MOQ)   |  u5u2   |
|  predictor_batch_size_compare |       tools_predictors/visualize/visualize_predictor_comparision_batch_size.py     |[link](https://pan.baidu.com/s/1xgfX0Cctvkrc-19LFNE4Ag)   |  24r3   |
|  predictive_performance_comparison |     tools_predictors/visualize/visualize_predictors_predictive_performance_comparison.py       |[link](https://pan.baidu.com/s/17wArHAjVJg4zavyGdTLdSA)   |   ebrh  |
|  predictor_normalize_ged |      tools_predictors/visualize/visualize_predictor_normalized_ged_comparison.py     |[link](https://pan.baidu.com/s/12evY1IPoxWNl3nNsVJ6Fcw)   |  h5zc   |
|  npenas_fixed_nasbench_101 |        tools_nas/close_domain/visualize_results.py     |[link](https://pan.baidu.com/s/1g_tfS_BDumYhfDUwmOlz8A)   |  ap6f   |
|  npenas_fixed_nasbench_201_cifar10 |      tools_nas/close_domain/visualize_results.py     |[link](https://pan.baidu.com/s/18dvpt4VCL4dxrZ4XxoMT_A)   |  rk9z   |
|  npenas_fixed_nasbench_201_cifar100 |      tools_nas/close_domain/visualize_results.py      |[link](https://pan.baidu.com/s/1Wc4zbS_ilYw_3SnTarQrdg)   |   nptc  |
|  npenas_fixed_nasbench_201_Imagenet |     tools_nas/close_domain/visualize_results.py      |[link](https://pan.baidu.com/s/1hvViRptwjsfFpS2DsxzSPA)   |   m16v  |
|  npenas_fixed_nasbench_101_batch_size_compare |    tools_nas/close_domain/visualize_results.py      |[link](https://pan.baidu.com/s/19lMg1rSa1HddkwOiRH5vBg)   |  xdn4   |
|  darts_results |          |[link](https://pan.baidu.com/s/1HF-NyTvoIUgjza5poW1W4w)   |  39xz   |
|  darts_results_new |          |[link](https://pan.baidu.com/s/1mbt24-qqHFMgJbuQBJrCKQ)   |  ikvy   |
<sub> * modify the parameters of the visualization script to view results. </sub>


## Acknowledge
1. [bananas](https://github.com/naszilla/bananas)
2. [pytorch_geometric](https://github.com/rusty1s/pytorch_geometric)
3. [NAS-Bench-101](https://github.com/google-research/nasbench)
4. [NAS-Bench-201](https://github.com/D-X-Y/NAS-Bench-201)
5. [MoCo](https://github.com/facebookresearch/moco)
6. [Semi-Supervised Neural Architecture Search](https://github.com/renqianluo/SemiNAS)
7. [NPENAS](https://github.com/auroua/NPENASv1)

## Contact
Chen Wei

email: weichen_3@stu.xidian.edu.cn, weichen@xupt.edu.cn