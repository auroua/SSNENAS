# Self-supervised Representation Learning for Evolutionary Neural Architecture Search

This repository contains code for paper [Self-supervised Representation Learning for Evolutionary Neural Architecture Search](https://arxiv.org/abs/2011.00186).

If you use the code please cite our paper.

    @article{Chen2020SSNENAS,
        title={Self-supervised Representation Learning for Evolutionary Neural Architecture Search},
        author={Chen Wei and Yiping Tang and Chuang Niu and Haihong Hu and Yue Wang and Jimin Liang},
        journal={ArXiv},
        year={2020},
        volume={abs/2011.00186}
    }

## Prerequisites
* Python 3.7
* Pytorch 1.3
* Tensorflow 1.14.0
* ptflops `pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git`
* torch-scatter `pip install torch-scatter==1.4.0`
* torch-sparse `pip install torch-sparse==0.4.3`
* torch-cluster `pip install torch-cluster==1.4.5`
* torch-spline-conv `pip install torch-spline-conv==1.1.1`

## Searching Environment
* Ubuntu 18.04
* cuda 10.0
* cudnn 7.5.1

## Usage
#### Clone this project
```bash
git clone https://github.com/auroua/SSNENAS
cd SSNENAS
```

#### Data Preparation
##### NASBench-101
1. Down load `NASBench-101` dataset first. We only use the `nasbench_only108.tfrecord` file.
2. Set the variable `nas_bench_101_base_path` in `config.py` to point to the folder containing the file `nasbench_only108.tfrecord`.
3. Run the following command to generate data files that are required by the code.
```bash
python nas_lib/data/nasbench_101_init.py
```

##### NASBench-201
1. Down load the `NASBench-201` dataset first. In this experiment, we use the `NASBench-201` dataset with version `v1_1-096897`, and the file name is `NAS-Bench-201-v1_1-096897.pth`.
2. Set the variable `nas_bench_201_base_path` in `config.py` to point to the folder containing the file `NAS-Bench-201-v1_1-096897.pth`.
3. Run the following command to generate data files that are required by the code.
```bash
python nas_lib/data/nasbench_201_init.py --dataname cifar10-valid
python nas_lib/data/nasbench_201_init.py --dataname cifar100
python nas_lib/data/nasbench_201_init.py --dataname ImageNet16-120
```

#### Prediction Analysis
##### SS_RL
Run the following command to train the model that contains the architecture embedding part of the neural predictor.
###### NASBench-101 search space
```bash
# save_dir: the output of model weights
python tools_predictors/train_predictor_rl.py --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/' --search_space 'nasbench_101' 
```

###### NASBench-201 search space    
```bash
# save_dir: the output of model weights
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_predictors/train_predictor_rl.py --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/' --search_space 'nasbench_201' --dataname 'cifar10-valid' 
```

##### SS_CCL
Run the following command to train the model that contains the architecture embedding part of the neural predictor.
###### NASBench-101 search space
```bash
# batch-size: Parameter N in Algorithm 1. The training batch size that determines the size of the negative pair. If you are using multiple gpus, multiple batch-size with the gpu count.
# train_samples: Parameter M in Algorithm 1.
# min_negative_size: Determine the number of negative pairs, which is slightly small than batch-size.
# multiprocessing-distributed: Using multiple gpus, set to True, else set to False.
# gpu: multiple gpus set to None, else set to 0.
python tools_predictors/train_predictor_ccl.py --search_space 'nasbench_101' --batch-size 40000 --train_samples 20000 --batch_step 1000 --min_negative_size 39850 --gpu 0 --multiprocessing-distributed False --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### NASBench-201 search space    
```bash
# batch-size: Parameter N in Algorithm 1. The training batch size that determines the size of the negative pair. If you are using multiple gpus, multiple batch-size with the gpu count.
# train_samples: Parameter M in Algorithm 1.
# min_negative_size: Determine the number of negative pairs, which is slightly small than batch-size.
# multiprocessing-distributed: Using multiple gpus, set to True, else set to False.
# gpu: multiple gpus set to None, else set to 0.
python tools_predictors/train_predictor_ccl.py --search_space 'nasbench_201' --batch-size 10000 --train_samples 5000 --batch_step 1000 --min_negative_size 9850 --gpu 0 --multiprocessing-distributed False --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

After the above pre-training, update the parameters `ss_rl_nasbench_101`, `ss_rl_nasbench_201`, `ss_ccl_nasbench_101`, and `ss_ccl_nasbench_201` to the pre-trained model file which is generated by the above code.

##### Predictive Performance Comparison
###### NASBench-101 search space
```bash
# predictor_list: The predictor type, it is a list type.
# load_dir: the pre-trained model paths, which is corresponding with the predictor types. 
python tools_predictors/predictor_finetune.py --predictor_list 'SS_RL' 'SS_CCL' --search_space 'nasbench_101' --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### NASBench-201 search space
```bash
# predictor_list: The predictor type, it is a list type.
# load_dir: the pre-trained model paths, which is corresponding with the predictor types.
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_predictors/predictor_finetune.py --predictor_list 'SS_RL' 'SS_CCL' --search_space 'nasbench_201' --save_dir '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

###### Visualize Results
Run the following command to visualize the comparison of algorithms
```bash
# result_path: the save_dir of the above commands.
python tools_predictors/predictor_finetune.py --result_path '/home/albert_wei/Disk_A/train_output_ssne_nas/test/'
```

#### Fixed Budget NPENAS
##### NASBench-101 search space
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_101 --algo_params nasbench_101 --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```
##### NASBench-101 search space fixed budget.
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_101 --algo_params nasbench_101_fixed --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```
##### NASBench-201 search space
```bash
# gpus: the number of gpus used to execute searching.
# save_dir: the output path.
# dataname: [`cifar10-valid`, `cifar100`, `ImageNet16-120`]
python tools_nas/close_domain/train_multiple_gpus_close_domain.py --trials 600 --search_space nasbench_201 --algo_params nasbench_201 --dataname 'cifar10-valid' --gpus 1 --save_dir /home/albert_wei/Disk_A/train_output_ssne_nas/test/
```

###### Visualize Results
Run the following command to visualize the comparison of algorithms. *Change the `save_dir` to the path of `save_dir` in the above step.*
```bash
python tools_close_domain/visualize_results.py --search_space nasbench_201 --save_dir /home/albert_wei/Disk_A/train_output_npenas/npenas_201/ --draw_type ERRORBAR
```

## Hardware Configuration

| CPU       | GPU     | Memory Size    |
| :-------------: | :----------: | :-----------: |
|  Intel Xeon E5-2650 v4 *2 | Titan V * 6   | 128G    |

## Acknowledge
1. [bananas](https://github.com/naszilla/bananas)
2. [pytorch_geometric](https://github.com/rusty1s/pytorch_geometric)
3. [NAS-Bench-101](https://github.com/google-research/nasbench)
4. [NAS-Bench-201](https://github.com/D-X-Y/NAS-Bench-201)
6. [MoCo](https://github.com/facebookresearch/moco)

## Contact
Chen Wei

email: weichen_3@stu.xidian.edu.cn, weichen@xupt.edu.cn